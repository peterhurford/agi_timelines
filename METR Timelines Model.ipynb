{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4a5d6b3-f5c7-4422-bcae-77134d4f4469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded libraries\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import squigglepy as sq\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "from functools import partial\n",
    "from typing import List, Tuple\n",
    "from scipy.optimize import minimize, Bounds\n",
    "from datetime import datetime, timedelta\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "\n",
    "O3_LAUNCH_DATE = datetime(2025, 4, 16)\n",
    "CLAUDE_3P7_LAUNCH_DATE = datetime(2025, 2, 24)\n",
    "\n",
    "\n",
    "def run_model(model, index_date=O3_LAUNCH_DATE):\n",
    "    samples = sq.sample(model, n=100_000, verbose=True)\n",
    "    pprint(sq.get_percentiles(samples, digits=0))\n",
    "    print('\\n-\\n')\n",
    "    samples_ = sq.get_percentiles(samples_to_date(samples, index_date=index_date))\n",
    "    samples_ = {k: v.strftime(\"%Y %b %d\") for k, v in samples_.items()}\n",
    "    pprint(samples_)\n",
    "    return samples\n",
    "\n",
    "\n",
    "def samples_to_date(samples, index_date=O3_LAUNCH_DATE):\n",
    "    date_converter = np.vectorize(lambda x: index_date + timedelta(days=int(np.ceil(x))))\n",
    "    return date_converter(samples)\n",
    "\n",
    "\n",
    "def calculate_doubling_time(start_task_length, agi_task_length, doubling_time, acceleration=1):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    start_task_length : scalar or distribution\n",
    "        Current hours needed for the reference task.\n",
    "    agi_task_length : scalar or distribution\n",
    "        Hours required for the task at AGI.\n",
    "    initial_doubling_time : scalar or distribution (days)\n",
    "        Doubling time at the *current* capability level.\n",
    "    acceleration : scalar or distribution\n",
    "        Multiplicative factor applied to the doubling time *after every doubling*.\n",
    "        • 1.0  → constant exponential growth (baseline).\n",
    "        • <1.0 → doubling time shrinks, giving super‑exponential growth.\n",
    "        • >1.0 → growth slows over time.\n",
    "    \"\"\"\n",
    "    doublings_needed = sq.dist_log(agi_task_length / start_task_length) / np.log(2)\n",
    "    if acceleration == 1:\n",
    "        return doublings_needed * doubling_time\n",
    "    else:\n",
    "        return doubling_time * (1 - acceleration**doublings_needed) / (1 - acceleration)\n",
    "\n",
    "\n",
    "def _pretty_time(hours: float) -> str:\n",
    "    \"\"\"Return a string with value + unit, choosing h / min / s.\"\"\"\n",
    "    if hours >= 1:\n",
    "        return f\"{hours:6.2f}hr\"\n",
    "    minutes = hours * 60\n",
    "    if minutes >= 1:\n",
    "        return f\"{minutes:6.2f}min\"\n",
    "    seconds = minutes * 60\n",
    "    return f\"{seconds:6.0f}sec\"\n",
    "    \n",
    "\n",
    "print('Loaded libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c516eca-0178-4834-a182-1d526686244c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step |    Date    |    Day |       Task | τ (d)\n",
      "-----------------------------------------------\n",
      "   0 | 2019‑02‑14 |      0 |       2sec | 260.0\n",
      "   1 | 2019‑11‑01 |    260 |       4sec | 247.0\n",
      "   2 | 2020‑07‑05 |    507 |       8sec | 234.6\n",
      "   3 | 2021‑02‑24 |    741 |      16sec | 222.9\n",
      "   4 | 2021‑10‑05 |    964 |      32sec | 211.8\n",
      "   5 | 2022‑05‑05 |   1176 |    1.07min | 201.2\n",
      "   6 | 2022‑11‑22 |   1377 |    2.13min | 191.1\n",
      "   7 | 2023‑06‑01 |   1568 |    4.27min | 181.6\n",
      "   8 | 2023‑11‑30 |   1750 |    8.53min | 172.5\n",
      "   9 | 2024‑05‑20 |   1922 |   17.07min | 163.9\n",
      "  10 | 2024‑10‑31 |   2086 |   34.13min | 155.7\n",
      "  11 | 2025‑04‑05 |   2242 |     1.14hr | 147.9\n",
      "  12 | 2025‑08‑31 |   2390 |     2.28hr | 140.5\n",
      "  13 | 2026‑01‑18 |   2530 |     4.55hr | 133.5\n",
      "  14 | 2026‑06‑01 |   2664 |     9.10hr | 126.8\n",
      "  15 | 2026‑10‑05 |   2790 |    18.20hr | 120.5\n",
      "  16 | 2027‑02‑03 |   2911 |    36.41hr | 114.4\n",
      "  17 | 2027‑05‑28 |   3025 |    72.82hr | 108.7\n",
      "  18 | 2027‑09‑14 |   3134 |   145.64hr | 103.3\n",
      "  19 | 2027‑12‑26 |   3237 |   291.27hr |  98.1  <-- reached target\n"
     ]
    }
   ],
   "source": [
    "def test_acceleration(\n",
    "    start_task_length: float,\n",
    "    agi_task_length: float,\n",
    "    initial_doubling_time: float,\n",
    "    acceleration: float = 1.0,\n",
    "    start_date: str | datetime | None = None,\n",
    "    date_fmt: str = \"%Y‑%m‑%d\",\n",
    "):\n",
    "    # Anchor date\n",
    "    if start_date is None:\n",
    "        start_date = datetime.today()\n",
    "    elif isinstance(start_date, str):\n",
    "        start_date = datetime.fromisoformat(start_date)\n",
    "\n",
    "    current_task = start_task_length\n",
    "    days_elapsed = 0.0\n",
    "    tau = initial_doubling_time\n",
    "    step = 0\n",
    "\n",
    "    header = f\"{'Step':>4} | {'Date':^10} | {'Day':>6} | {'Task':>10} | τ (d)\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "\n",
    "    while current_task < agi_task_length:\n",
    "        date = start_date + timedelta(days=days_elapsed)\n",
    "        print(f\"{step:4d} | {date.strftime(date_fmt)} | \"\n",
    "              f\"{int(days_elapsed):6d} | {_pretty_time(current_task):>10} | {tau:5.1f}\")\n",
    "\n",
    "        current_task *= 2            # actual doubling\n",
    "        days_elapsed += tau\n",
    "        tau *= acceleration          # super‑/sub‑exponential effect\n",
    "        step += 1\n",
    "\n",
    "    # final line after exceeding target\n",
    "    date = start_date + timedelta(days=days_elapsed)\n",
    "    print(f\"{step:4d} | {date.strftime(date_fmt)} | \"\n",
    "          f\"{int(days_elapsed):6d} | {_pretty_time(current_task):>10} | {tau:5.1f}  <-- reached target\")\n",
    "\n",
    "\n",
    "test_acceleration(\n",
    "    start_task_length=2/60/60, # GPT2\n",
    "    agi_task_length=167, \n",
    "    initial_doubling_time=260,\n",
    "    acceleration=0.95,\n",
    "    start_date=\"2019-02-14\", # GPT2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "060a2daa-f4c0-467d-a741-065d2ee50ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT‑2 to o3: (329, 0.9)\n",
      "GPT‑2 to Claude 3.7 Sonnet: (331, 0.9)\n",
      "GPT‑3.5 Turbo to Claude 3.7 Sonnet: (88, 1.0)\n",
      "GPT‑3.5 Turbo to o3: (88, 1.0)\n",
      "Claude 3 Opus to o3: (101, 1.0)\n",
      "GPT‑4o to o3: (97, 1.0)\n",
      "Claude 3.5 Sonnet (old) to o3: (141, 0.9)\n",
      "o1 preview to o3: (107, 0.9)\n",
      "GPT‑3.5 Turbo to Claude 3.7 Sonnet: (88, 1.0)\n",
      "Claude 3 Opus to Claude 3.7 Sonnet: (102, 1.0)\n",
      "GPT‑4o to Claude 3.7 Sonnet: (98, 1.0)\n",
      "Claude 3.5 Sonnet (old) to Claude 3.7 Sonnet: (157, 0.9)\n",
      "o1 preview to Claude 3.7 Sonnet: (112, 1.0)\n"
     ]
    }
   ],
   "source": [
    "def calendar_days_for_doublings(\n",
    "    doublings: np.ndarray,\n",
    "    initial_doubling_time: float,\n",
    "    acceleration: float\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Super‑exponential growth law from Chin & You (2024).\"\"\"\n",
    "    if np.isclose(acceleration, 1.0):\n",
    "        # pure exponential (constant doubling time)\n",
    "        return doublings * initial_doubling_time\n",
    "    return (\n",
    "        initial_doubling_time\n",
    "        * (1 - acceleration ** doublings)\n",
    "        / (1 - acceleration)\n",
    "    )\n",
    "\n",
    "\n",
    "def estimate_growth_parameters(\n",
    "    observations: List[Tuple[str, datetime, float]],\n",
    "    baseline_date: datetime | None = None,\n",
    "    baseline_task_hours: float | None = None,\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Returns (τ₀, α) where\n",
    "        τ₀ = initial doubling time (days at baseline capability)\n",
    "        α  = multiplicative change in τ after each doubling\n",
    "    \"\"\"\n",
    "    if baseline_date is None:\n",
    "        baseline_date = observations[0][1]\n",
    "    if baseline_task_hours is None:\n",
    "        baseline_task_hours = observations[0][2]\n",
    "\n",
    "    doublings: np.ndarray = np.log(\n",
    "        [hours / baseline_task_hours for _, _, hours in observations]\n",
    "    ) / np.log(2)\n",
    "\n",
    "    elapsed_days: np.ndarray = np.array(\n",
    "        [(release_date - baseline_date).days for _, release_date, _ in observations],\n",
    "        dtype=float,\n",
    "    )\n",
    "\n",
    "    def mse_loss(theta: np.ndarray) -> float:\n",
    "        τ0, α = theta\n",
    "        if τ0 <= 0 or not 0 < α < 2:\n",
    "            return np.inf  # penalise nonsense regions\n",
    "        prediction = calendar_days_for_doublings(doublings, τ0, α)\n",
    "        return np.mean((prediction - elapsed_days) ** 2)\n",
    "\n",
    "    initial_guess = np.array([260.0, 0.95])\n",
    "    bounds = Bounds([1e-6, 0.9], [np.inf, 1.0]) # # bound acceleration to 0.9-1, days must be positive\n",
    "    result = minimize(mse_loss, x0=(260.0, 0.95), method=\"L-BFGS-B\", bounds=bounds, options={\"maxiter\": 10_000})\n",
    "    t_hat, a_hat = result.x\n",
    "    return round(float(t_hat)), round(float(a_hat), 3)\n",
    "\n",
    "\n",
    "def print_estimation(data):\n",
    "    start_model = data[0][0]\n",
    "    end_model = data[-1][0]\n",
    "    print(f\"{start_model} to {end_model}: {estimate_growth_parameters(data)}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "observed_models: List[Tuple[str, datetime, float]] = [\n",
    "    # model                       # release date         # task length\n",
    "    (\"GPT‑2\",                     datetime(2019, 2, 14),  2/3600),   # 2 s\n",
    "    (\"GPT‑3.5 Turbo\",             datetime(2023, 6, 13), 36/3600),   # 36 s\n",
    "    (\"Claude 3 Opus\",             datetime(2024, 3,  4),  6/60),     # 6 min\n",
    "    (\"GPT‑4o\",                    datetime(2024, 5, 13),  9/60),     # 9 min\n",
    "    (\"Claude 3.5 Sonnet (old)\",   datetime(2024, 6, 20), 18/60),     # 18 min\n",
    "    (\"o1 preview\",                datetime(2024, 9, 12), 22/60),     # 22 min\n",
    "    (\"Claude 3.5 Sonnet (new)\",   datetime(2024,10, 22), 28/60),     # 28 min\n",
    "    (\"o1\",                        datetime(2024,12,  5), 39/60),     # 39 min\n",
    "    (\"Claude 3.7 Sonnet\",         datetime(2025, 2, 24), 59/60),     # 59 min\n",
    "    (\"o3\",                        datetime(2025, 4, 16),  1+45/60),  # 1 h 45 min\n",
    "]\n",
    "\n",
    "print_estimation(observed_models)\n",
    "print_estimation(observed_models[:-1])\n",
    "print_estimation(observed_models[1:-1])\n",
    "for i in range(1, 6):\n",
    "    print_estimation(observed_models[i:])\n",
    "for i in range(1, 6):\n",
    "    print_estimation(observed_models[i:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f230eccb-1174-46c1-9488-748742717e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step |    Date    |    Day |       Task | τ (d)\n",
      "-----------------------------------------------\n",
      "   0 | 2024‑06‑20 |      0 |   18.00min | 126.0\n",
      "   1 | 2024‑10‑24 |    126 |   36.00min | 123.5\n",
      "   2 | 2025‑02‑24 |    249 |     1.20hr | 121.0\n",
      "   3 | 2025‑06‑25 |    370 |     2.40hr | 118.6\n",
      "   4 | 2025‑10‑22 |    489 |     4.80hr | 116.2\n",
      "   5 | 2026‑02‑15 |    605 |     9.60hr | 113.9\n",
      "   6 | 2026‑06‑09 |    719 |    19.20hr | 111.6\n",
      "   7 | 2026‑09‑28 |    830 |    38.40hr | 109.4\n",
      "   8 | 2027‑01‑16 |    940 |    76.80hr | 107.2\n",
      "   9 | 2027‑05‑03 |   1047 |   153.60hr | 105.1\n",
      "  10 | 2027‑08‑16 |   1152 |   307.20hr | 103.0  <-- reached target\n"
     ]
    }
   ],
   "source": [
    "test_acceleration(\n",
    "    start_task_length=18/60, # Claude 3.5\n",
    "    agi_task_length=167,\n",
    "    initial_doubling_time=126,\n",
    "    acceleration=0.98,\n",
    "    start_date=\"2024-06-20\", # Claude 3.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e0475ac-76ee-40d8-8dcb-af4fd2f311a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 100000/100000 [00:06<00:00, 15075.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 100000/100000 [00:07<00:00, 12712.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1097,\n",
      " 5: 1249,\n",
      " 10: 1340,\n",
      " 20: 1459,\n",
      " 30: 1550,\n",
      " 40: 1634,\n",
      " 50: 1714,\n",
      " 60: 1799,\n",
      " 70: 1895,\n",
      " 80: 2015,\n",
      " 90: 2193,\n",
      " 95: 2351,\n",
      " 99: 2673}\n",
      "\n",
      "-\n",
      "\n",
      "{1: '2028 Feb 26',\n",
      " 5: '2028 Jul 28',\n",
      " 10: '2028 Oct 27',\n",
      " 20: '2029 Feb 22',\n",
      " 30: '2029 May 25',\n",
      " 40: '2029 Aug 16',\n",
      " 50: '2029 Nov 05',\n",
      " 60: '2030 Jan 29',\n",
      " 70: '2030 May 04',\n",
      " 80: '2030 Sep 01',\n",
      " 90: '2031 Feb 27',\n",
      " 95: '2031 Aug 04',\n",
      " 99: '2032 Jun 20'}\n"
     ]
    }
   ],
   "source": [
    "def metr_model():\n",
    "    days = calculate_doubling_time(start_task_length=1, agi_task_length=167, doubling_time=212, acceleration=1) # Variables from METR paper\n",
    "    measurement_error_variance = sq.invlognorm(0.8, 1.5) # Add easurement error on tasks: SD fit to trend variance from Figure 12\n",
    "    return days * measurement_error_variance\n",
    "\n",
    "_ = run_model(metr_model, index_date=CLAUDE_3P7_LAUNCH_DATE) # Results should look similar to Figure 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cca18c-09a0-4cda-aee2-f1fedb464204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 100000/100000 [00:06<00:00, 15783.27it/s]\n",
      " 91%|████████████████████████████████████████████████████████████████████▌      | 91374/100000 [00:07<00:00, 12535.39it/s]"
     ]
    }
   ],
   "source": [
    "def metr_model_with_o3():\n",
    "    days = calculate_doubling_time(start_task_length=1.75, agi_task_length=167, doubling_time=118, acceleration=1) # Use o3 task length, o3 launch date, and the 2024-2025 doubling time\n",
    "    measurement_error_variance = sq.invlognorm(0.8, 1.5) # Add measurement error on tasks: SD fit to trend variance from Figure 12\n",
    "    return days * measurement_error_variance\n",
    "\n",
    "_ = run_model(metr_model_with_o3, index_date=O3_LAUNCH_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9258965e-db47-4631-bf6c-63e76b9221bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The simpler model with static variables from my Substack\n",
    "def simple_model():\n",
    "    days = calculate_doubling_time(start_task_length=3.75/60, agi_task_length=167, doubling_time=165, acceleration=1)\n",
    "    shift = 100\n",
    "    return days - shift\n",
    "\n",
    "_ = run_model(simple_model, index_date=O3_LAUNCH_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9db226-d328-45c8-a35a-0a416c04b6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('## START task length (displayed in min) ##')\n",
    "\n",
    "# -- DEFINE CURRENT BEST\n",
    "current_best = 1.75 # o3 task length at 50% reliability? (in hours)\n",
    "\n",
    "# -- DEFINE ADJUSTMENTS\n",
    "elicitation_boost = sq.mixture([[0.4, 1], # Can you get a boost to scores by iterating on scaffolding and other elicitation techniques? 40% chance no, 30% chance you can get a 1.1-1.3x speed up, 30% chance of 1.2-1.5x.\n",
    "                                [0.3, sq.norm(1.1, 1.2)],\n",
    "                                [0.3, sq.norm(1.2, 1.5)]])\n",
    "                               \n",
    "reliability_needed = sq.mixture([[0.2, 0.5], # What amount of reliability will we need? Probability distribution over hypotheses\n",
    "                                 [0.5, 0.8],\n",
    "                                 [0.1, 0.9],\n",
    "                                 [0.1, 0.95],\n",
    "                                 [0.1, 0.99]])\n",
    "\n",
    "def reliability_count_to_penalty(reliability):\n",
    "    r = np.asarray(reliability, dtype=float)\n",
    "    reliability = np.array([0.50, 0.80, 0.90, 0.95, 0.99])\n",
    "    penalty = np.array([1.0, 0.25, 0.25**2, 0.25**3, 0.25**4])\n",
    "    matches = r[..., None] == reliability\n",
    "    hit_any = matches.any(axis=-1)\n",
    "    idx = matches.argmax(axis=-1)\n",
    "    out = np.full_like(r, np.nan, dtype=float)\n",
    "    out[hit_any] = penalty[idx[hit_any]]\n",
    "    return out\n",
    "\n",
    "task_type_penalty = sq.mixture([[0.1, 1],                          # 10% chance that METR's software tasks are sufficient for AGI\n",
    "                                [0.5, 1 / sq.lognorm(5, 100)],     # 50% chance that true AGI tasks are 5-100x (lognorm) harder than METR's software tasks\n",
    "                                [0.4, 1 / sq.lognorm(50, 1000)]])  # 40% chance that true AGI tasks are 50-1000x (lognorm) harder than METR's software tasks\n",
    "\n",
    "# -- CREATE DISTRIBUTION\n",
    "# Start with current best, add elicitation boost\n",
    "start_task_length = current_best * elicitation_boost\n",
    "\n",
    "# add reliability penalty\n",
    "start_task_length = start_task_length * sq.dist_fn(reliability_needed, reliability_count_to_penalty)\n",
    "\n",
    "# Add task type penalty\n",
    "start_task_length *= task_type_penalty\n",
    "\n",
    "# Add a minimum value of 1sec\n",
    "start_task_length = sq.dist_max(1/60/60, start_task_length)\n",
    "\n",
    "# Show samples in minutes (naturally in hours)\n",
    "sq.get_percentiles((start_task_length * 60) @ 100_000, digits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b91a8e4-007b-4b91-aba9-237102467302",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('## Task length needed for AGI (displayed in hrs) ##')\n",
    "agi_task_length = sq.norm(80, 2000, credibility=80, lclip=40)\n",
    "sq.get_percentiles(agi_task_length @ 100_000, digits=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacf9251-36ef-4b49-a07c-9ef269defe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('## DOUBLING TIME (displayed in days) ##')\n",
    "doubling_time = sq.mixture([[0.4, 212],\n",
    "                            [0.2, 118],\n",
    "                            [0.1, 320],\n",
    "                            [0.3, sq.lognorm(lognorm_mean=126, lognorm_sd=40)]])\n",
    "sq.get_percentiles(doubling_time @ 100_000, digits=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151bb954-9b59-4dc5-bc20-fec1a8965124",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('## ACCELERATION (displayed in days)')\n",
    "acceleration = sq.mixture([[0.7, 1],\n",
    "                           [0.3, 1 - sq.lognorm(0.005, 0.1, credibility=80)]])\n",
    "sq.get_percentiles(acceleration @ 100_000, digits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d0ea11-e4a4-4f51-bc01-0c1e1c7d68e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('## SHIFT (displayed in days) ##')\n",
    "shift = sq.lognorm(30, 30*5, credibility=80, lclip=0)\n",
    "sq.get_percentiles(shift @ 100_000, digits=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9a416d-b871-411e-a806-13caaf19790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapted_metr_model():\n",
    "    start_task_length_ = start_task_length * (2 ** (shift / doubling_time))\n",
    "    days = calculate_doubling_time(start_task_length_, agi_task_length, doubling_time, acceleration)\n",
    "    measurement_error_variance = sq.invlognorm(0.8, 1.5) # Add measurement error on tasks: SD fit to trend variance from Figure 12\n",
    "    return days * measurement_error_variance\n",
    "\n",
    "samples = run_model(adapted_metr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c0bf0-9e89-4568-95f4-098bf15b8338",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('## DISTRIBUTION OF AGI ARRIVAL DATE ##')\n",
    "# Convert datetime samples to years\n",
    "agi_years = [s / 365 + 2025 for s in samples]\n",
    "pctiles = sq.get_percentiles(agi_years, percentiles=[1, 2, 3, 4, 5, 10, 15, 20, 25, 35, 50, 60, 75, 80, 90, 95])\n",
    "pprint([\n",
    "    ((str(o[0]) + '%: ' + str(round(o[1], 1))) if o[1] < 2100 else '>2100') \n",
    "    for o in pctiles.items()\n",
    "])\n",
    "print('')\n",
    "print('')\n",
    "print('## DISTRIBUTION OF RELATIVE AGI ARRIVAL DATE ##')\n",
    "pprint([\n",
    "    ((str(o[0]) + '%: ' + str(round(o[1] - 2025, 1))) if o[1] < 2100 else '>75') + ' years from now' \n",
    "    for o in pctiles.items()\n",
    "])\n",
    "print('(Mean: {} years from now)'.format(int(round(np.mean([t - 2025 for t in agi_years])))))\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('## AGI ARRIVAL DATE BY BIN ##')\n",
    "\n",
    "def bin_agi_yrs(low=None, hi=None):\n",
    "    low = 2025 if low is None else low\n",
    "    if hi is None:\n",
    "        r = np.mean([y >= low for y in agi_years])\n",
    "    else:\n",
    "        r = np.mean([(y >= low) and (y <= hi) for y in agi_years])\n",
    "    return round(r * 100, 1)\n",
    "\n",
    "\n",
    "year_pairs = [[2025, 2026],\n",
    "              [2026, 2027],\n",
    "              [2027, 2028],\n",
    "              [2028, 2029],\n",
    "              [2029, 2030],\n",
    "              [2030, 2032],\n",
    "              [2032, 2035],\n",
    "              [2035, 2040],\n",
    "              [2040, 2050],\n",
    "              [2050, 2060],\n",
    "              [2060, 2070],\n",
    "              [2070, 2080],\n",
    "              [2080, 2090],\n",
    "              [2090, 2100]]\n",
    "for y in year_pairs:\n",
    "    if y[0] == y[1] - 1:\n",
    "        print('{}: {}%'.format(y[0], bin_agi_yrs(y[0], y[1])))\n",
    "    else:\n",
    "        print('{}-{}: {}%'.format(y[0], y[1]-1, bin_agi_yrs(y[0], y[1])))\n",
    "print('>{}: {}%'.format(2100, bin_agi_yrs(low=2100)))\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "print('## AGI ARRIVAL DATE BY YEAR ##')\n",
    "for y in list(range(2025, 2035)) + list(range(2035, 2100, 5)):\n",
    "    print('By EOY {}: {}%'.format(y, bin_agi_yrs(hi=y+1)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9d01b0-192d-4a6b-893c-4ac4a5ec5961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import squigglepy as sq\n",
    "\n",
    "DAYS_PER_QUARTER = 365 / 4\n",
    "\n",
    "\n",
    "def billions_formatter(x, pos):\n",
    "    if x >= 1e9:\n",
    "        return f\"{x/1e9:.1f}B\"\n",
    "    if x >= 1e6:\n",
    "        return f\"{x/1e6:.1f}M\"\n",
    "    if x >= 1e3:\n",
    "        return f\"{x/1e3:.1f}K\"\n",
    "    if x <= 0.5:\n",
    "        return f\"1/{1/x:.0f}\"\n",
    "    return f\"{x:.0f}\"\n",
    "\n",
    "\n",
    "def _quarter_labels(n: int, start_year: int = 2025) -> list[str]:\n",
    "    return [f\"{start_year + q // 4}Q{q % 4 + 1}\" for q in range(n + 1)]\n",
    "\n",
    "\n",
    "def _y_ticks(lo: int = -13, hi: int = 13) -> list[int]:\n",
    "    return [2 ** k for k in range(lo, hi + 1)]\n",
    "\n",
    "\n",
    "def _first_curve(order, traj, reference, above):\n",
    "    cmp = np.greater_equal if above else np.less_equal\n",
    "    for idx in order:\n",
    "        if np.all(cmp(traj[idx], reference)):\n",
    "            return idx\n",
    "    return order[0]\n",
    "\n",
    "\n",
    "def plot_exponential_growth(\n",
    "    doubling_time_days,\n",
    "    starting_hours,\n",
    "    agi_task_length,\n",
    "    shift=0,\n",
    "    acceleration=1,\n",
    "    n_quarters: int = 40,\n",
    "    n_samples: int = 10_000,\n",
    "    n_traces: int = 100,\n",
    ") -> None:\n",
    "    tau0 = sq.sample(doubling_time_days, n=n_samples)\n",
    "    accel = sq.sample(acceleration, n=n_samples)\n",
    "    secret = sq.sample(shift, n=n_samples)\n",
    "    agi = sq.sample(sq.dist_min(2**13, agi_task_length), n=n_samples)\n",
    "    start = sq.sample(starting_hours, n=n_samples) * 2 ** (secret / tau0)\n",
    "\n",
    "    quarters = np.arange(n_quarters + 1)\n",
    "    traj = np.zeros((n_samples, len(quarters)))\n",
    "    clip_idx = np.full(n_samples, len(quarters), dtype=int)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        tau = tau0[i]\n",
    "        val = start[i]\n",
    "        for j in range(len(quarters)):\n",
    "            if val >= 2**13:\n",
    "                traj[i, j:] = 2**13\n",
    "                clip_idx[i] = j\n",
    "                break\n",
    "            traj[i, j] = val\n",
    "            val *= 2 ** (DAYS_PER_QUARTER / tau)\n",
    "            tau *= accel[i]\n",
    "\n",
    "    reached = traj >= agi[:, None]\n",
    "    first_hit = np.argmax(reached, axis=1)\n",
    "    first_hit[np.all(~reached, axis=1)] = len(quarters)\n",
    "\n",
    "    order = np.argsort(first_hit)\n",
    "    median_idx = order[len(order) // 2]\n",
    "    median_curve = traj[median_idx]\n",
    "\n",
    "    idx10 = _first_curve(order[int(0.10 * n_samples):], traj, median_curve, above=True)\n",
    "    idx90 = _first_curve(order[: int(0.90 * n_samples)][::-1], traj, median_curve, above=False)\n",
    "\n",
    "    highlights = {\n",
    "        \"10 % earliest\": (traj[idx10], first_hit[idx10], clip_idx[idx10], \"b--\"),\n",
    "        \"Median\": (median_curve, first_hit[median_idx], clip_idx[median_idx], \"b-\"),\n",
    "        \"90 % latest\": (traj[idx90], first_hit[idx90], clip_idx[idx90], \"b--\"),\n",
    "    }\n",
    "\n",
    "    plt.figure(figsize=(11, 6))\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    for i in rng.choice(n_samples, min(n_traces, n_samples), replace=False):\n",
    "        end_q = min(first_hit[i], clip_idx[i], len(quarters) - 1)\n",
    "        plt.plot(\n",
    "            quarters[: end_q + 1],\n",
    "            traj[i, : end_q + 1],\n",
    "            color=\"tab:blue\",\n",
    "            lw=0.3,\n",
    "            alpha=0.25,\n",
    "        )\n",
    "        marker = \"rx\" if first_hit[i] < len(quarters) else \"ko\"\n",
    "        plt.plot(quarters[end_q], traj[i, end_q], marker, ms=4, alpha=0.6)\n",
    "\n",
    "    for label, (curve, hit_q, clip_q, style) in highlights.items():\n",
    "        end_q = min(hit_q, clip_q, len(quarters) - 1)\n",
    "        plt.plot(quarters[: end_q + 1], curve[: end_q + 1], style, lw=2, label=label)\n",
    "        marker = \"rx\" if hit_q < len(quarters) else \"ko\"\n",
    "        plt.plot(quarters[end_q], curve[end_q], marker, ms=7)\n",
    "\n",
    "    plt.plot([], [], \"rx\", ms=7, label=\"AGI reached\")\n",
    "    plt.plot([], [], \"ko\", ms=7, label=\"AGI not by EOY2037\")\n",
    "\n",
    "    plt.yscale(\"log\", base=2)\n",
    "    plt.yticks(_y_ticks())\n",
    "    plt.gca().yaxis.set_major_formatter(FuncFormatter(billions_formatter))\n",
    "    plt.xticks(quarters, _quarter_labels(n_quarters), rotation=90)\n",
    "    plt.grid(ls=\"--\", alpha=0.7)\n",
    "    plt.ylabel(\"Task length (hours) -- note log scale\")\n",
    "    plt.tight_layout()\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "\n",
    "plot_exponential_growth(\n",
    "    doubling_time_days=doubling_time,\n",
    "    starting_hours=start_task_length,\n",
    "    agi_task_length=agi_task_length,\n",
    "    shift=shift,\n",
    "    acceleration=acceleration,\n",
    "    n_quarters=51,\n",
    "    n_samples=100_000,\n",
    "    n_traces=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0452ce3-eb22-48da-a332-6bd4b2682f46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
